{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju9Qhv9fnjHI"
      },
      "source": [
        "# What's in a developmental phase? Training dynamics & Behavioural characterizations of grammar learning\n",
        "*Authors: Oskar van der Wal & Marianne de Heer Kloots*\n",
        "\n",
        "In this notebook, we are going to explore the grammar learning dynamics of a *decoder-only* language model (LM): Pythia-160m.\n",
        "The *Pythia* model suite is interesting, because it provides us with intermediate checkpoints during training (Biderman et al., 2023). Moreover, for the smaller sized models, we'll also have access to 10 different seedsâ€”which change the random initialization of the model parameters at the start as well as the order of the training dataâ€”over the same training run.\n",
        "\n",
        "We'll use the performance on the BLiMP dataset as a way to quantify the model's grammar capabilities. To save you time, we have prepared the results on BLiMP for 24 checkpoints in advance. The first part of this notebook shows examples of how to load and visualize the BLiMP results.\n",
        "\n",
        "The second part will show how Latent State Models trained on the internal parts of the LMs (i.e., parameters of the weight and bias matrices) can be used to find distinct phases during training (Hu et al., 2023). It would be really interesting if low-level mathematical features of the model tells something about higher-level capabilities, but it's not clear whether that should be the case! Do these phases overlap with phases in Pythia's grammar learning?\n",
        "\n",
        "**Relevant papers:**\n",
        "- ðŸ“„ [BLiMP (Warstadt et al., 2020)](https://aclanthology.org/2020.tacl-1.25.pdf)\n",
        "- ðŸ“„ [Pythia (Biderman et al., 2023)](https://proceedings.mlr.press/v202/biderman23a/biderman23a.pdf)\n",
        "- ðŸ“„ [Latent State Models (Hu et al., 2023)](https://arxiv.org/html/2308.09543v3)\n",
        "\n",
        "Â© 2024 The authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTipD-VpnjHL"
      },
      "source": [
        "## 0-Setup\n",
        "You can use the following code to set things up + install the required dependencies when running on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxa8_zqYnjHM"
      },
      "outputs": [],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # Note: because Altair V4 instead of V5 is used in Colab, some settings\n",
        "    # will be different in the notebook.\n",
        "\n",
        "    # Installing some dependencies\n",
        "    !pip3 install altair hmmlearn\n",
        "\n",
        "    import altair as alt\n",
        "    alt.data_transformers.disable_max_rows()\n",
        "\n",
        "    !wget https://raw.githubusercontent.com/ANN-HumLang/ANN-HumLang-tutorials/main/pythia/training_map.py\n",
        "    MATRIX_METRICS_PATH=\"https://raw.githubusercontent.com/ANN-HumLang/ANN-HumLang-tutorials/main/pythia/matrix_metrics_160m.tsv\"\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook\")\n",
        "\n",
        "    import altair as alt\n",
        "    alt.data_transformers.enable(\"vegafusion\")\n",
        "    MATRIX_METRICS_PATH=\"matrix_metrics_160m.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n2-KBvPnjHO"
      },
      "source": [
        "## 1-Loading BLiMP results\n",
        "Let's have a look at the dataframe containing all BLiMP results for the different Pythia 160m training checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "PEyNpE99njHO",
        "outputId": "67aa679e-e64c-4a1a-a4fc-bac34146c690"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "blimp = pd.read_csv(\"https://raw.githubusercontent.com/ANN-HumLang/ANN-HumLang-tutorials/main/pythia/blimp_160m.tsv\", sep=\"\\t\")\n",
        "blimp = blimp[~(blimp[\"field\"] == \"Aggregate\")]\n",
        "blimp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BXaibNfnjHP"
      },
      "source": [
        "BLiMP consists of sentence-pairs that consist of a correct vs. an incorrect variant. The accuracy on the grammar tasks are measured by testing whether the LM assigns a higher probability (logit) to the correct sentence. For example (from `determiner_noun_agreement`):\n",
        "> Craig explored that grocery **store**.\n",
        "\n",
        "vs.\n",
        "\n",
        "> Craig explored that grocery **stores**.\n",
        "\n",
        "These sentence-pairs are grouped into 67 *paradigms*. These paradigms are grouped into different *phenomena*, which in turn are part of one of the 4 *fields*: morphology, syntax, semantics, or syntaxsemantics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwFO80OQnjHP",
        "outputId": "2201a7c5-351a-4ab2-ffa6-97f7fe5c874d"
      },
      "outputs": [],
      "source": [
        "print(\"-\"*10)\n",
        "print(\"Information about the BLiMP dataset:\")\n",
        "print(\"Number of paradigms: {}\".format(len(blimp.paradigm.unique())))\n",
        "print(\"Number of phenomena: {}\".format(len(blimp.phenomenon.unique())))\n",
        "print(\"Number of fields: {}\".format(len(blimp.field.unique())))\n",
        "\n",
        "print(\"-\"*10)\n",
        "print(\"Information about the Pythia checkpoints:\")\n",
        "print(\"Number of seeds: {}\".format(len(blimp.seed.unique())))\n",
        "print(\"Number of steps: {}\".format(len(blimp.step.unique())))\n",
        "print(\"First step: {}\".format(blimp.step.min()))\n",
        "print(\"Last step: {}\".format(blimp.step.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atniNMS6njHQ"
      },
      "source": [
        "In case you need the full list of all paradigms, phenomena, or fields, you can use the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ5BmtodnjHQ",
        "outputId": "6e48f2a3-9274-4a49-9371-1716db7b21dc"
      },
      "outputs": [],
      "source": [
        "print(list(blimp.paradigm.unique()))\n",
        "print(list(blimp.phenomenon.unique()))\n",
        "print(list(blimp.field.unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2iFeJqknjHR"
      },
      "source": [
        "Since the results dataframe contains both accuracy and std for each BLiMP paradigm, we'll separate these for convenience. We'll also remove the std from `blimp`, so you can continue using this short-hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "i08bZTrKnjHR",
        "outputId": "fe328064-40a0-4e6b-9680-e38ccfbabdd3"
      },
      "outputs": [],
      "source": [
        "blimp_acc   = blimp[blimp[\"metric\"] == \"acc\"]\n",
        "blimp_std   = blimp[blimp[\"metric\"] == \"std\"]\n",
        "\n",
        "blimp       = blimp[blimp[\"metric\"] == \"acc\"]\n",
        "blimp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE1Dkz0DnjHS"
      },
      "source": [
        "## 3-Visualizing the BLiMP results\n",
        "In the following examples, Altair is used for visualizing the BLiMP results. It is possible to pass a dataframe directly, but using a URL instead reduces the size of the notebook considerably.\n",
        "\n",
        "Of course, feel free to use the visualization library you're most comfortable with!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSL8DHx7yGap"
      },
      "outputs": [],
      "source": [
        "BLIMP_URL = \"https://raw.githubusercontent.com/ANN-HumLang/ANN-HumLang-tutorials/main/pythia/blimp_160m_acc.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyaA36i8njHS"
      },
      "outputs": [],
      "source": [
        "import altair as alt\n",
        "\n",
        "def get_rule_selecting_step(blimp, y_min=0.0):\n",
        "    \"\"\"Helper function used for visualizing the step at your mouse's cursor in the figure.\"\"\"\n",
        "\n",
        "    # Create a selection that chooses the nearest point & selects based on x-value\n",
        "    try:\n",
        "        nearest = alt.selection_point(nearest=True, on=\"pointerover\",\n",
        "                              fields=[\"step\"], empty=False)\n",
        "    except AttributeError:\n",
        "        nearest = alt.selection(type='single', nearest=True, on='mouseover',\n",
        "                        fields=['step'], empty='none')\n",
        "\n",
        "    # Transparent selectors across the chart. This is what tells us\n",
        "    # the x-value of the cursor\n",
        "    try:\n",
        "        selectors = alt.Chart(blimp).mark_point().encode(\n",
        "            x=\"step:Q\",\n",
        "            opacity=alt.value(0),\n",
        "        ).add_params(\n",
        "            nearest\n",
        "        )\n",
        "    except AttributeError:\n",
        "        selectors = alt.Chart(blimp).mark_point().encode(\n",
        "            x=\"step:Q\",\n",
        "            opacity=alt.value(0),\n",
        "        ).add_selection(\n",
        "            nearest\n",
        "        )\n",
        "\n",
        "    # Draw a rule at the location of the selection\n",
        "    rules = alt.Chart(blimp).mark_rule(color=\"gray\").encode(\n",
        "        x=\"step:Q\",\n",
        "    ).transform_filter(\n",
        "        nearest\n",
        "    )\n",
        "\n",
        "    # Draw text labels near the points, and highlight based on selection\n",
        "    text = rules.mark_text(align=\"left\", dx=5, dy=-5).encode(\n",
        "        text=alt.condition(nearest, \"step:Q\", alt.value(\" \")), y=alt.datum(y_min)\n",
        "    )\n",
        "\n",
        "    return selectors, rules, text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "C1fynPs4njHS",
        "outputId": "3639a614-56c9-45b8-f9f5-f402c2e0b103"
      },
      "outputs": [],
      "source": [
        "line = alt.Chart(BLIMP_URL).mark_line(opacity=0.5).encode(\n",
        "    x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\")),\n",
        "    y=alt.Y('mean(score):Q', scale=alt.Scale(domain=[0.5, 0.85]), title=\"BLiMP (mean)\"),\n",
        "    color=alt.Color(\"seed:N\"),\n",
        "    #tooltip=[\"seed\",\"step\",\"mean(score)\"],\n",
        ")\n",
        "\n",
        "selectors, rules, text = get_rule_selecting_step(blimp, y_min=0.5)\n",
        "\n",
        "alt.layer(\n",
        "    line, selectors, rules, text\n",
        ").properties(\n",
        "    width=600, height=300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xrr3l0ScnjHT",
        "outputId": "c8ada0ec-bd36-4a8e-c544-02b874767800"
      },
      "outputs": [],
      "source": [
        "alt.Chart(BLIMP_URL).mark_line(opacity=0.5).encode(\n",
        "    x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\")),\n",
        "    y=alt.Y('score:Q'),\n",
        "    color=alt.Color(\"seed:N\"),\n",
        ").facet(facet=\"paradigm:N\", columns=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "5SGUO5MQnjHT",
        "outputId": "c7d21084-fede-4efb-e413-8a8012c45a3b"
      },
      "outputs": [],
      "source": [
        "# If you only want to look at one paradigm more closely\n",
        "paradigm=\"blimp_superlative_quantifiers_2\"\n",
        "y_min=0.3\n",
        "y_max=0.85\n",
        "title=f\"{paradigm} (mean)\"\n",
        "\n",
        "base = alt.Chart(BLIMP_URL)\n",
        "\n",
        "bands = base.mark_errorband(extent=\"ci\").encode(\n",
        "    x=\"step:Q\",\n",
        "    y=alt.Y('score:Q', scale=alt.Scale(domain=[y_min, y_max])),\n",
        ")\n",
        "\n",
        "line = base.mark_line(opacity=0.5).encode(\n",
        "    x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\")),\n",
        "    y=alt.Y('mean(score):Q', scale=alt.Scale(domain=[y_min, y_max])),\n",
        ")\n",
        "\n",
        "selectors, rules, text = get_rule_selecting_step(blimp, y_min=y_min)\n",
        "\n",
        "# Put the five layers into a chart and bind the data\n",
        "alt.layer(\n",
        "    bands, line, selectors, rules, text\n",
        ").transform_filter(\n",
        "    f'datum.paradigm == {paradigm}'\n",
        ").properties(\n",
        "    width=600, height=300, title=title\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "AQzZDx7HnjHT",
        "outputId": "38376975-c799-40f3-9cc9-5fe6e3840eed"
      },
      "outputs": [],
      "source": [
        "line = alt.Chart(blimp).mark_line(opacity=0.8).encode(\n",
        "    x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\")),\n",
        "    y=alt.Y('mean(score):Q'),\n",
        "    color=alt.Color(\"phenomenon:N\"),\n",
        ")\n",
        "\n",
        "selectors, rules, text = get_rule_selecting_step(blimp)\n",
        "\n",
        "alt.layer(\n",
        "    line, selectors, rules, text\n",
        ").properties(\n",
        "    width=600, height=300\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "lqHSO320njHU",
        "outputId": "41e9bb6f-142d-4d13-8853-2cdd98920b11"
      },
      "outputs": [],
      "source": [
        "lines = alt.Chart(blimp).mark_line(opacity=0.8).encode(\n",
        "    x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\")),\n",
        "    y=alt.Y('mean(score):Q', scale=alt.Scale(domain=[0.5, 1])),\n",
        "    color=alt.Color(\"field:N\"),\n",
        ")\n",
        "\n",
        "selectors, rules, text = get_rule_selecting_step(blimp, y_min=0.5)\n",
        "\n",
        "# Put the five layers into a chart and bind the data\n",
        "alt.layer(\n",
        "    lines, selectors, rules, text\n",
        ").properties(\n",
        "    width=600, height=300\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbEISarCnjHU"
      },
      "source": [
        "## 4-Training Latent State Models\n",
        "\n",
        "Now that we have explored the progression of the various BLiMP phenomena during training, we'll now check out another tool in our training dynamics tool-box: Latent State Models. Following Hu et al. (2023), we are going to test whether these models, induced on how general model matrix properties change during training (e.g., the mean of the weight matrices, $\\mu_w$), can help us understand the different phases during training.\n",
        "\n",
        "The first step in inducing an HMM, is selecting the right number of states. We'll select $N$ such that it minimizes AIC and BIC, and maximizes the log-likelihood (LL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZvy-_NZ3huq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "3-0F5_9vnjHU",
        "outputId": "a7243702-bea4-4f02-a69f-72612fb379b1"
      },
      "outputs": [],
      "source": [
        "from training_map import HMMTrainingMapSelection\n",
        "\n",
        "matrix_metrics = pd.read_csv(MATRIX_METRICS_PATH, sep=\"\\t\")\n",
        "TS = HMMTrainingMapSelection(matrix_metrics)\n",
        "TS.show_model_selection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaQai8xCnjHU"
      },
      "source": [
        "Based on the graph above, we'll select $N=3$ hidden states, which gives us the following diagram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "Y2NF4p-knjHV",
        "outputId": "3c081ae0-e790-4c69-b3a9-35891f9c2fb0"
      },
      "outputs": [],
      "source": [
        "# Select N=3 components from model selection plot above\n",
        "training_map = TS.get_training_map(3)\n",
        "training_map.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFQ9GIuEnjHV"
      },
      "source": [
        "Hu et al. (2023) use the distribution over the states the models visit during training (\"Bag of States\") as one way to compare across seeds. For our Pythia-160m model, we find that these are very similar! So there is not much variation between the different seeds. But perhaps these differences reflect in important differences between the models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZsrCQSnjHV",
        "outputId": "1191bcc4-fe78-4a9d-c15d-df52b4fc110d"
      },
      "outputs": [],
      "source": [
        "training_map.bag_of_states_distributions # shape = (seed x state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jevuyLXTnjHV"
      },
      "source": [
        "Check out the slides/paper for a description of the metrics used for training the HMM Latent State Model, but here you can find an overview as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzEERJs_njHV",
        "outputId": "1b6910ba-0b40-47e9-b80b-d33a584637c7"
      },
      "outputs": [],
      "source": [
        "training_map.data.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDNEXxj0njHV"
      },
      "source": [
        "How do the states changes over time? Let's plot these on top of one of the model matrix properties.\n",
        "\n",
        "Note that we have pre-computed the model metrics for all training checkpoints, instead of only a selection as we did for BLiMP!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "uZzW_q0UnjHW",
        "outputId": "dbb2f406-6813-4cec-c4ab-f831405bcc60"
      },
      "outputs": [],
      "source": [
        "training_map.show_training_states(\"trace\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zZnD5YpnjHW"
      },
      "source": [
        "## 5-Labelling Checkpoints\n",
        "As we've seen above, we can use the latent state models to get a \"training map\" that labels each checkpoint according to one of the three states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "AvFrubaEnjHW",
        "outputId": "c7bf4407-959a-4a84-cc74-b8c59e7b79e0"
      },
      "outputs": [],
      "source": [
        "# Get df from (seed, step) -> state\n",
        "training_map.labeled_checkpoints.set_index([\"seed\",\"step\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "EnZSI8HAnjHW",
        "outputId": "b5ec2dac-e040-414d-b1fd-7e8f436e6bf8"
      },
      "outputs": [],
      "source": [
        "def reformat_blimp(df, training_map, column=\"paradigm\"):\n",
        "    \"\"\"\n",
        "    Reformat BLiMP dataframe, and add state labels as new column.\n",
        "\n",
        "    column options ['paradigm', 'phenomenon', 'field']\"\"\"\n",
        "    assert column in ['paradigm', 'phenomenon', 'field']\n",
        "\n",
        "    if not column==\"paradigm\":\n",
        "        df = df[[\"seed\", \"step\", \"score\", column]].groupby([\"seed\", \"step\", column]).mean().reset_index()\n",
        "    df_ = df.pivot(index=[\"seed\", \"step\"], columns=[column], values=[\"score\"]).score.reset_index()\n",
        "    df_.columns.name = None\n",
        "    df_ = df_.set_index([\"seed\",\"step\"])\n",
        "    df_[\"average\"] = df_.mean(axis=1)\n",
        "\n",
        "    cols = list(df_.columns)\n",
        "\n",
        "    # Add state for each checkpoints\n",
        "    labeled_checkpoints = training_map.labeled_checkpoints.set_index([\"seed\",\"step\"])\n",
        "    df_ = pd.merge(df_, labeled_checkpoints, left_index=True, right_index=True)\n",
        "    return df_[[\"state\",]+cols].reset_index()\n",
        "\n",
        "paradigms_labeled = reformat_blimp(blimp, training_map, column=\"paradigm\")\n",
        "paradigms_labeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "qpt3OGS9njHW",
        "outputId": "010b4bf5-0cab-4b11-ff29-ae8ff7cd7352"
      },
      "outputs": [],
      "source": [
        "def plot_labeled_ckpts_blimp(data, metric):\n",
        "    line = alt.Chart(data).mark_line().encode(\n",
        "        x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\"), axis=alt.Axis(title=\"step\")),\n",
        "        y=alt.Y(metric+':Q', scale=alt.Scale(zero=False), axis=alt.Axis(title=metric)),\n",
        "    )\n",
        "\n",
        "    dots = alt.Chart(data).mark_circle(size=100).encode(\n",
        "        x=alt.X('step:Q',scale=alt.Scale(type=\"sqrt\"), axis=alt.Axis(title=\"step\")),\n",
        "        y=alt.Y(metric+':Q', scale=alt.Scale(zero=False)),\n",
        "        color=alt.Color(\"state:N\", scale=alt.Scale(range=training_map.plot_config[\"state_colors\"])),\n",
        "    )\n",
        "\n",
        "    selectors, rules, text = get_rule_selecting_step(blimp)\n",
        "\n",
        "    # rules = alt.Chart(pd.DataFrame({\n",
        "    #     'step': [10000],\n",
        "    #     'color': ['red']\n",
        "    #     })).mark_rule().encode(\n",
        "    #     x='step',\n",
        "    #     color=alt.Color('color:N', scale=None)\n",
        "    #     )\n",
        "\n",
        "    return (line+dots+selectors+rules+text).facet(column=\"seed\")\n",
        "\n",
        "plot_labeled_ckpts_blimp(paradigms_labeled, \"blimp_adjunct_island\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "SRJgJbcnnjHX",
        "outputId": "e98d08b0-8688-426c-bdec-a7042601c183"
      },
      "outputs": [],
      "source": [
        "phenomena_labeled = reformat_blimp(blimp, training_map, column=\"phenomenon\")\n",
        "\n",
        "# print(paradigms_labeled.phenomenon.unique())\n",
        "# Choose from:\n",
        "# ['Anaphor agreement' 'Argument structure' 'Binding'\n",
        "# 'Control/raising' 'Determiner-Noun agreement' 'Ellipsis' 'Filler gap'\n",
        "# 'Irregular forms' 'Island effects' 'NPI licensing' 'Quantifiers'\n",
        "# 'Subject-Verb agreement']\n",
        "\n",
        "plot_labeled_ckpts_blimp(phenomena_labeled, \"Island effects\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F2hcwTNWnjHX",
        "outputId": "dd0895dc-43c7-4ac6-f67f-ee9f73b6d5bd"
      },
      "outputs": [],
      "source": [
        "fields_labeled = reformat_blimp(blimp, training_map, column=\"field\")\n",
        "\n",
        "plots = []\n",
        "for field in ['morphology','semantics','syntax','syntaxsemantics']:\n",
        "    plots.append(plot_labeled_ckpts_blimp(fields_labeled, field))\n",
        "alt.vconcat(*plots)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
